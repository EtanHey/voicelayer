# Flow Bar â€” VoiceLayer Floating Widget

> Native macOS SwiftUI app that shows voice state and provides stop/toggle/replay controls.
> Communicates with VoiceLayer MCP server via Unix domain socket.

## Vision

Free, open-source Wispr Flow alternative focused on Claude Code. A floating pill at the bottom of the screen that shows what VoiceLayer is doing (speaking, recording, transcribing) and lets the user control it without touching terminal commands.

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       Unix socket        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  VoiceLayer MCP     â”‚  â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚  Flow Bar        â”‚
â”‚  (Bun/TypeScript)   â”‚  /tmp/voicelayer.sock     â”‚  (SwiftUI app)   â”‚
â”‚                     â”‚                           â”‚                  â”‚
â”‚  Creates socket     â”‚  JSON newline-delimited   â”‚  Reconnecting    â”‚
â”‚  Sends state events â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º    â”‚  client          â”‚
â”‚  Receives commands  â”‚  â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚  Sends commands  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Socket ownership:** VoiceLayer creates `/tmp/voicelayer.sock` on startup. Flow Bar connects as a client and reconnects on disconnect. If VoiceLayer isn't running, the bar shows "disconnected" state.

## Socket Protocol (v1)

### Events (VoiceLayer â†’ Bar)

```json
{"type": "state", "state": "idle"}
{"type": "state", "state": "speaking", "text": "What do you think about...", "voice": "jenny"}
{"type": "state", "state": "recording", "mode": "vad", "silence_mode": "quick"}
{"type": "state", "state": "recording", "mode": "ptt"}
{"type": "state", "state": "transcribing"}

{"type": "speech", "detected": true}
{"type": "speech", "detected": false}

{"type": "transcription", "text": "The user said this"}

{"type": "error", "message": "Mic not available", "recoverable": true}
{"type": "error", "message": "STT backend failed", "recoverable": false}
```

### Commands (Bar â†’ VoiceLayer)

```json
{"cmd": "stop"}
{"cmd": "replay"}
{"cmd": "toggle", "scope": "all", "enabled": false}
{"cmd": "toggle", "scope": "tts", "enabled": false}
{"cmd": "toggle", "scope": "mic", "enabled": false}
```

### State Machine

```
idle â†’ speaking â†’ idle                              (voice_speak)
idle â†’ speaking â†’ recording â†’ transcribing â†’ idle   (voice_ask, speech detected)
idle â†’ speaking â†’ recording â†’ idle                  (voice_ask, no speech / stop)
any  â†’ error â†’ (previous state or idle)
```

### Contracts

- `speaking â†’ idle` fires when afplay process exits (TTS playback done)
- `recording â†’ transcribing` fires when rec stops and whisper/STT starts
- `transcribing â†’ idle` fires after transcription result is sent
- `speech` events fire during `recording` state only, true/false as VAD processes chunks
- Toggle scope matches existing flag files: `all` | `tts` | `mic`
- Per-user socket path deferred (single-user macOS for now)

## SwiftUI Bar Design

### Position & Size

- **Position:** Bottom of screen, 60% from left edge (20% right of center)
- **Size:** ~280x40pt pill with rounded corners (24pt radius)
- **Window level:** Always on top (`.floating` window level)
- **Background:** Translucent vibrancy material (`.ultraThinMaterial`)
- **When idle:** Semi-transparent, subtle presence
- **When active:** Full opacity with state-appropriate colors

### Visual States

```
IDLE:          [ ğŸ™ VoiceLayer          ]   Muted gray, subtle
SPEAKING:      [ â–¶  ||||||||||||    â–    ]   Blue (#4A90D9), animated bars, stop button
RECORDING:     [ ğŸ”´ ||||||||||||    âœ“   ]   Red pulse (#E54D4D), live bars, finish button
TRANSCRIBING:  [ âŸ³  Processing...      ]   Blue spinner, brief state
ERROR:         [ âš   Mic not found   Ã—  ]   Yellow (#E5A84D), auto-dismiss 3s
DISCONNECTED:  [ â—‹  Disconnected       ]   Dim gray, no controls
```

### Controls Per State

| State | Left | Center | Right |
|-------|------|--------|-------|
| idle | mic icon (gray) | "VoiceLayer" | â€” |
| speaking | play icon (blue) | waveform bars (animated) | stop (â– ) |
| recording | red dot (pulsing) | waveform bars (animated) | finish (âœ“) |
| transcribing | spinner | "Processing..." | â€” |
| error | warning icon | error message | dismiss (Ã—) |
| disconnected | empty circle | "Disconnected" | â€” |

### Interactions

- **Click stop** during speaking â†’ `{"cmd": "stop"}` â†’ kills TTS playback
- **Click finish** during recording â†’ `{"cmd": "stop"}` â†’ ends recording, triggers transcription
- **Click pill** when idle â†’ expand to show toggle controls (TTS on/off, mic on/off)
- **Right-click** â†’ replay last message (`{"cmd": "replay"}`)
- **Drag** â†’ reposition the bar (persist position in UserDefaults)

### Animations

- **Waveform bars:** 5-7 vertical bars that animate height based on `speech.detected` events. Idle shimmer when waiting, active bounce when speech detected.
- **Recording pulse:** Red dot with subtle scale pulse animation (1.0 â†’ 1.2 â†’ 1.0, 1.5s cycle)
- **State transitions:** 200ms crossfade between states
- **Error:** Slide in from bottom, auto-dismiss after 3s with fade out

## VoiceLayer Changes Required

### New: Socket Server (`src/socket-server.ts`)

- Create Unix domain socket at `/tmp/voicelayer.sock` on MCP server startup
- Accept multiple client connections (bar + potential future clients)
- Parse incoming JSON commands, dispatch to existing handlers
- Clean up socket file on shutdown (SIGTERM/SIGINT)

### Modified: State Emission Points

| File | Where | Event |
|------|-------|-------|
| `src/tts.ts` | `speak()` start | `state: speaking` |
| `src/tts.ts` | `playAudioNonBlocking()` process exit | `state: idle` |
| `src/input.ts` | `recordToBuffer()` start | `state: recording` |
| `src/input.ts` | VAD chunk loop | `speech: detected` |
| `src/input.ts` | `recordToBuffer()` finish | `state: transcribing` |
| `src/input.ts` | `waitForInput()` after transcribe | `state: idle` + `transcription` |
| `src/mcp-server.ts` | error catches | `error` event |

### Modified: Command Handlers

Socket `stop` command â†’ write `/tmp/voicelayer-stop` (reuses existing mechanism)
Socket `replay` command â†’ call `playAudioNonBlocking(getHistoryEntry(0))` directly
Socket `toggle` command â†’ call existing toggle logic (write/delete flag files)

## SwiftUI Project Structure

```
flow-bar/
â”œâ”€â”€ Package.swift              # SPM package definition
â”œâ”€â”€ Sources/
â”‚   â”œâ”€â”€ FlowBarApp.swift       # @main, NSApplication setup, floating window
â”‚   â”œâ”€â”€ BarView.swift          # Main pill view with state-driven UI
â”‚   â”œâ”€â”€ WaveformView.swift     # Animated vertical bars
â”‚   â”œâ”€â”€ SocketClient.swift     # Unix socket connection + reconnect
â”‚   â”œâ”€â”€ VoiceState.swift       # ObservableObject state model
â”‚   â””â”€â”€ Theme.swift            # Colors, sizes, animation constants
â””â”€â”€ Resources/
    â””â”€â”€ Assets.xcassets         # App icon
```

## v1 Scope (MVP)

- Socket server in VoiceLayer (create, accept, emit events, receive commands)
- State events: idle, speaking, recording, transcribing
- Commands: stop, toggle
- SwiftUI bar: state colors, stop/finish button, idle label
- Basic waveform animation (shimmer, not audio-driven)
- Reconnection logic (retry every 2s)
- Error display (auto-dismiss)

## v1.5 Scope (Live Dictation)

Live transcription in the bar â€” words appear as you speak, not just at the end.

**STT pipeline change:** Batch â†’ streaming.
- Current: `rec â†’ WAV file â†’ whisper-cli â†’ full text`
- New: `rec stdout â†’ pipe to whisper-cli --stream â†’ parse partial results in real-time`

**New protocol events:**
```json
{"type": "transcription", "text": "The user", "partial": true}
{"type": "transcription", "text": "The user said this", "partial": true}
{"type": "transcription", "text": "The user said this thing", "partial": false}
```

**Bar changes:**
- Recording state shows live text scrolling below the waveform bars
- Text animates in word-by-word as partials arrive
- Final (partial=false) is what gets returned to Claude
- Bar pill expands vertically to fit ~2 lines of text, then scrolls

**whisper.cpp streaming:**
- `whisper-cli --stream` reads from stdin, outputs partial transcripts
- Processes in ~1-2 second windows with overlap
- Latency: ~500ms for first words to appear
- Needs `--print-realtime` flag for streaming output

## v2 Scope (Later)

- Audio-level driven waveform (`{"type": "audio_level", "rms": 0.42}`)
- Pause/resume recording
- Replay controls (right-click menu with history)
- Draggable positioning with persistence
- Expanded idle view (toggles, status)
- Launch at login (Login Items)
- Context-aware STT post-processing (developer vocabulary)

## Development Approach

Red-green-refactor TDD:
1. Socket server tests first (Bun-side)
2. Protocol serialization tests
3. State emission at each integration point
4. SwiftUI previews for each visual state
5. Integration test: MCP â†’ socket â†’ bar state change
